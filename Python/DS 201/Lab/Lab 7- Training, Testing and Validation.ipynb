{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ben Porter\n",
    "### This Lab is open from 10/25 at 6 am to 10/25 at 3:30 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set called Highway1 (used by  by Carl Hoffstedt in his paper: https://rdrr.io/rforge/alr4/man/Highway1.html) relate the automobile accident rate, in accidents per million vehicle miles to several potential terms. The data include 39 sections of large Highways in the state of Minnesota in 1973. The goal of this analysis is to see how the rate variable are affetcted by some of the variables that are highly correlated with the rate and finding out which ones affect the rate variable the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame contains the following columns:\n",
    "\n",
    "adt - average daily traffic count in thousands\n",
    "\n",
    "trks - truck volume as a percent of the total volume\n",
    "\n",
    "lane - total number of lanes of traffic\n",
    "\n",
    "acpt - number of access points per mile\n",
    "\n",
    "sigs - number of signalized interchanges per mile\n",
    "\n",
    "itg - number of freeway-type interchanges per mile\n",
    "\n",
    "slim - speed limit in 1973\n",
    "\n",
    "len - length of the Highway segment in miles\n",
    "\n",
    "lwid - lane width, in feet\n",
    "\n",
    "shld - width in feet of outer shoulder on the roadway\n",
    "\n",
    "htype - An indicator of the type of roadway or the source of funding for the road; \"mc\" for major collector, \"fai\" for Federal interstate highways, \"pa\" for principal arterial highway, and \"ma\" for major arterial highways\n",
    "\n",
    "rate - 1973 accident rate per million vehicle miles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please note that we are using a tiny data set with 39 rows and 11 columns in this lab. So, when we model and fit data, the accuracy is not that good and predictions do not look good as well. We are just learning to use these different models, so it is okay for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sm\n",
    "highway1 = pd.read_csv('Highway1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each problem is worth 10 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "This data came from R package which uses index starting at 1 unlike in python where indices  start at 0. When  you upload highway1 data to jupyter notebook, you will see an unnecessory column that says column 0. Also remove the column indicating hiway types as it is a string.\n",
    "Train a linear model with rate as a dependent variable, and 10 numerical columns as dependent variables. Make sure to add a constant in the data so that you also get an intercept in the output. Look at the summary of the model, report the $R^2$ value, find out two variables that have p-values of more than 90% and remove them from the data. Name this new data set that has 8 important independent variables and  rate as a dependent variable as newdata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwy1=highway1.drop(highway1[['hwy']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwy1=hwy1.drop(hwy1.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hwy1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-465376bf1c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhwy1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sigs1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'scatter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlm1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rate ~ sigs1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhighway1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mxmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhighway1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhighway1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hwy1' is not defined"
     ]
    }
   ],
   "source": [
    "newdata=hwy1.plot('sigs1','rate',kind='scatter')\n",
    "lm1=sm.ols('rate ~ sigs1',data=highway1).fit()\n",
    "xmin=highway1.trks.min()\n",
    "xmax=highway1.trks.max()\n",
    "    \n",
    "X=hwy1.drop(columns=['rate'])\n",
    "Y=lm1.params[0]+lm1.params[1]*X\n",
    "plt.plot(X,Y, color=\"darkgreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>rate</td>       <th>  R-squared:         </th> <td>   0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   21.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 25 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>4.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:13:58</td>     <th>  Log-Likelihood:    </th> <td> -72.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    39</td>      <th>  AIC:               </th> <td>   149.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    37</td>      <th>  BIC:               </th> <td>   152.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.0129</td> <td>    0.326</td> <td>    9.249</td> <td> 0.000</td> <td>    2.353</td> <td>    3.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigs1</th>     <td>    1.8023</td> <td>    0.392</td> <td>    4.600</td> <td> 0.000</td> <td>    1.008</td> <td>    2.596</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.030</td> <th>  Durbin-Watson:     </th> <td>   1.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.018</td> <th>  Jarque-Bera (JB):  </th> <td>   6.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.959</td> <th>  Prob(JB):          </th> <td>  0.0329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.725</td> <th>  Cond. No.          </th> <td>    2.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   rate   R-squared:                       0.364\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     21.16\n",
       "Date:                Fri, 25 Oct 2019   Prob (F-statistic):           4.82e-05\n",
       "Time:                        14:13:58   Log-Likelihood:                -72.772\n",
       "No. Observations:                  39   AIC:                             149.5\n",
       "Df Residuals:                      37   BIC:                             152.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.0129      0.326      9.249      0.000       2.353       3.673\n",
       "sigs1          1.8023      0.392      4.600      0.000       1.008       2.596\n",
       "==============================================================================\n",
       "Omnibus:                        8.030   Durbin-Watson:                   1.774\n",
       "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                6.829\n",
       "Skew:                           0.959   Prob(JB):                       0.0329\n",
       "Kurtosis:                       3.725   Cond. No.                         2.10\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm=sm.ols(formula='rate ~ sigs1', data=hwy1).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "In this problem we will just pick the variable named 'sigs1' and the 'rate' variable from newdata. We will use test/train validation method to see how our model does. Denote sigs1 column by x and rate column by y. Split the data x and y with a 80, 20 rule to x_train, x_test, y_train and y_test. This means that you are dividing x data to two data sets of x_train and x_test with 80% and 20 % of the data randomly and the same for y. Report the shapes of these 4 data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python has a package called sklearn that has this split function inside it.\n",
    "# Please import the following package that wil help us splitting the data.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[['sigs1']]\n",
    "y=[['rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.33 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-103858bfa383>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m-> 2100\u001b[1;33m                                               default_test_size=0.25)\n\u001b[0m\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1780\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[1;32m-> 1782\u001b[1;33m                                                 train_size)\n\u001b[0m\u001b[0;32m   1783\u001b[0m         )\n\u001b[0;32m   1784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.33 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about train and test splitting here.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Now train a linear regression model using x_train and y_train. Do not forget to add a constant to the x_train data. Report your $R^2$ and and coefficients. Now make a prediction of y values using the data set x_test. Make sure to add constant to this x_test data before making predictions. Name this predictions as y_pred. You just need to use the predict function with your model explained here \n",
    "https://www.statsmodels.org/dev/examples/notebooks/generated/predict.html\n",
    "Now display y_pred and y_test side by side to see how the predictions match up. Finally find the $R^2$ for the test data. Formula for the test set $R^2$ is goven below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import r2_score\n",
    "#r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "Repeat probem 3 without adding the constant this time. This just means that your model is simply $y \\approx bx$ instead of $y \\approx a+bx$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "In problem 1, you created a data set with only important columns. Use this data set to fit a multivariable regression model by splitting data to training and testing with 80, 20 rule. Report your training set $R^2$, coefficients and  predicted values and test set $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am extremely confused and have spent hours trying to understand how to do this lab and I cannot figure it out for the life of me. I feel like I am missing something and I can't cotinue on through the lab without whatever I am missing since each of the problems build off the last problem. If there is something I could do to better understand these functions I would love to do it but at this moment I am unable to finish this lab effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
